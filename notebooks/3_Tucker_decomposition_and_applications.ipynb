{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/111495zjy/ASP_coursework/blob/main/notebooks/3_Tucker_decomposition_and_applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IlyaKisil/dpm-coursework.git\n",
        "%cd /content/dpm-coursework\n",
        "\n",
        "!./boostrap-venv.sh"
      ],
      "metadata": {
        "id": "j6BTVJmAviMx",
        "outputId": "dcb63792-a3b2-4529-c05d-209b172378c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dpm-coursework'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 143 (delta 3), reused 2 (delta 0), pack-reused 133 (from 1)\u001b[K\n",
            "Receiving objects: 100% (143/143), 3.38 MiB | 27.26 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/dpm-coursework\n",
            "./boostrap-venv.sh: line 7: conda: command not found\n",
            "./boostrap-venv.sh: line 11: conda: command not found\n",
            "Processing ./binder/coursework\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (6.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from coursework==0.1.1) (1.14.1)\n",
            "Collecting hottbox (from coursework==0.1.1)\n",
            "  Downloading hottbox-0.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from hottbox->coursework==0.1.1) (1.6.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->coursework==0.1.1) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->coursework==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->coursework==0.1.1) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->coursework==0.1.1) (2025.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->coursework==0.1.1)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->coursework==0.1.1) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->coursework==0.1.1) (5.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->coursework==0.1.1) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->hottbox->coursework==0.1.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->hottbox->coursework==0.1.1) (3.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->coursework==0.1.1) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->coursework==0.1.1) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->coursework==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->coursework==0.1.1) (0.2.13)\n",
            "Downloading hottbox-0.3.2-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: coursework\n",
            "  Building wheel for coursework (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coursework: filename=coursework-0.1.1-py3-none-any.whl size=166608 sha256=7b1c8e437767f81406aa695954c26d41da0d28f8bed6ab8397355a7320c91b3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ggv8euby/wheels/27/4a/5d/4506a6e044a1c3d7b88bb81db683a16b6a1fb55a0614720dd3\n",
            "Successfully built coursework\n",
            "Installing collected packages: jedi, hottbox, coursework\n",
            "Successfully installed coursework-0.1.1 hottbox-0.3.2 jedi-0.19.2\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "Installed kernelspec dpm-coursework in /root/.local/share/jupyter/kernels/dpm-coursework\n",
            "./boostrap-venv.sh: line 13: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ep7blCpsxSN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j-wvkkBdOA2c"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "eQtUbZvtxTtU",
        "outputId": "d792f04d-b17e-46c1-f2b5-1f6d1cd0fe0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.5\n",
            "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tdh13k87OA2f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from hottbox.core import Tensor, TensorTKD\n",
        "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
        "from hottbox.utils.generation import residual_tensor\n",
        "from coursework.data import get_image, plot_tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3ZtRIc-rOA2g"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "EuJUA2oWOA2g"
      },
      "source": [
        "[Return to Table of Contents](./0_Table_of_contents.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0CfhNNNOA2h"
      },
      "source": [
        "# Tucker Decomposition\n",
        "\n",
        "<img src=\"https://github.com/IlyaKisil/dpm-coursework/blob/master/notebooks/imgs/TensorTKD.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "In previous [assignment](./2_Efficient_representation_of_multidimensional_arrays.ipynb), you have been provided materials which cover efficient representations of mutlidimensional arrays of data, such as the Tucker form. In this module, you will take a closer look at it and the assiciated computational methods.\n",
        "\n",
        "\n",
        "Any tensor of arbitrarily large order can be decomposed in the Tucker form. As illustrated above, a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I \\times J \\times K}$ can be represented as a dense core tensor $\\mathbf{\\underline{G}}$ and a set of factor matrices $\\mathbf{A} \\in \\mathbb{R}^{I \\times Q}, \\mathbf{B} \\in \\mathbb{R}^{J \\times R}$ and $\\mathbf{C} \\in\n",
        "\\mathbb{R}^{K \\times P}$\n",
        "\n",
        "$$\n",
        "\\mathbf{\\underline{X}} = \\mathbf{\\underline{G}} \\times_1 \\mathbf{A} \\times_2 \\mathbf{B} \\times_3 \\mathbf{C} = \\Big[    \\mathbf{\\underline{G}} ;  \\mathbf{A},  \\mathbf{B}, \\mathbf{C}      \\Big]\n",
        "$$\n",
        "\n",
        "\n",
        "On practice, there exist several computational methods to accomplish this all of which are combined into a Tucker Decomposition framework. The two most commonly used algorithms are:\n",
        "1. Higher Order Singular Value Decomposition ([HOSVD](#Higher-Order-Singular-Value-Decomposition-(HOSVD)))\n",
        "1. Higher Order Orthogonal Iteration ([HOOI](#Higher-Order-Orthogonal-Iteration-(HOOI)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "HNpp6dOkOA2i"
      },
      "source": [
        "**Higher Order Singular Value Decomposition (HOSVD)**\n",
        "\n",
        "The HOSVD is a special case of the Tucker decomposition, in which all the factor matrices are constrained to be orthogonal. They are computed as truncated version of the left singular matrices of all possible mode-$n$ unfoldings of tensor $\\mathbf{\\underline{X}}$:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{X}_{(1)} &= \\mathbf{U}_1  \\mathbf{\\Sigma}_1 \\mathbf{V}_1^T \\quad \\rightarrow \\quad \\mathbf{A} = \\mathbf{U}_1[1:R_1]\\\\\n",
        "\\mathbf{X}_{(2)} &= \\mathbf{U}_2  \\mathbf{\\Sigma}_2 \\mathbf{V}_2^T \\quad \\rightarrow \\quad \\mathbf{B} = \\mathbf{U}_2[1:R_2] \\\\\n",
        "\\mathbf{X}_{(3)} &= \\mathbf{U}_3  \\mathbf{\\Sigma}_3 \\mathbf{V}_3^T \\quad \\rightarrow \\quad \\mathbf{C} = \\mathbf{U}_3[1:R_3] \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "After factor matrices are obtained, the core tensor $\\mathbf{\\underline{G}}$ is computed as\n",
        "\n",
        "$$\n",
        "\\mathbf{\\underline{G}} = \\mathbf{\\underline{X}} \\times_1 \\mathbf{A}^T \\times_2 \\mathbf{B}^T \\times_3 \\mathbf{C}^T        \n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4qfXOBhOA2i"
      },
      "source": [
        "# Higher Order Orthogonal Iteration (HOOI)\n",
        "\n",
        "# HOOI algorithm is another special case of the Tuker decomposition. Like HOSVD, it decomposes a tensor into a dense core tensor and orthogonal factor matrices. The difference between the two lies in the fact that in HOOI the factor matrices are optimized iteratively using an Alternating Least Squares (ALS) approach. In other words, the tucker representation $[ \\mathbf{\\underline{G}};\\mathbf{A}^{(1)}, \\mathbf{A}^{(2)}, \\cdots,\\mathbf{A}^{(N)} ]$ of the given tensor $\\mathbf{\\underline{X}}$ is obtained through the HOOI as follows\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&\\mathbf{\\underline{Y}} = \\mathbf{\\underline{X}} \\times_1 \\mathbf{A}^{(1)T} \\times_2 \\cdots \\times_{n-1} \\mathbf{A}^{(n-1)T} \\times_{n+1} \\mathbf{A}^{(n+1)} \\times \\cdots \\times_N \\mathbf{A}^{(N)} \\\\\n",
        "&\\mathbf{A}^{(n)} \\leftarrow R_n \\text{ leftmost singular vectors of } \\mathbf{Y}_{(n)}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The above is repeated until convergence, then the core tensor $\\mathbf{\\underline{G}} \\in \\mathbb{R}^{R_1 \\times R_2 \\times \\cdots \\times R_N}$ is computed as\n",
        "\n",
        "$$\n",
        "\\mathbf{\\underline{G}} = \\mathbf{\\underline{X}} \\times_1 \\mathbf{A}^{(1)T}  \\times_2 \\mathbf{A}^{(2)T} \\times_3 \\cdots  \\times_N \\mathbf{A}^{(N)T}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "Z8v3RhMCOA2i"
      },
      "source": [
        "### Multi-linear rank\n",
        "\n",
        "*   列表项\n",
        "*   列表项\n",
        "\n",
        "\n",
        "\n",
        "The **multi-linear rank** of a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ is the $N$-tuple $(R_1, \\dots, R_N)$ where each $R_n$ is the rank of the subspace spanned by mode-$n$ fibers, i.e. $R_n = \\text{rank} \\big( \\mathbf{X}_{(n)} \\big)$. Thus, for our order-$3$ tensor the multi-linear rank is $(R_1, R_2, R_3)$. Multi-linear rank provides flexibility in compression and approximation of the original tensor.\n",
        "\n",
        "> **NOTE:** For a tensor of order $N$ the values $R_1, R_2, \\dots , R_N$ are not necessarily the same, whereas, for matrices (tensors of order 2) the equality $R_1 = R_2$ always holds, where $R_1$ and $R_2$ are the matrix column rank and row rank respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc1qEql_OA2j"
      },
      "source": [
        "# Performing tensor decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yOwEGhAZOA2j",
        "outputId": "d522bfe0-2e0c-4e71-8d82-6875352bdbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tucker representation of a tensor with multi-linear rank=(4, 5, 6).\n",
            "Factor matrices represent properties: ['mode-0', 'mode-1', 'mode-2']\n",
            "With corresponding latent components described by (5, 6, 7) features respectively.\n",
            "\n",
            "\tFactor matrices\n",
            "Mode-0 factor matrix is of shape (5, 4)\n",
            "Mode-1 factor matrix is of shape (6, 5)\n",
            "Mode-2 factor matrix is of shape (7, 6)\n",
            "\n",
            "\tCore tensor\n",
            "This tensor is of order 3 and consists of 120 elements.\n",
            "Sizes and names of its modes are (4, 5, 6) and ['mode-0', 'mode-1', 'mode-2'] respectively.\n"
          ]
        }
      ],
      "source": [
        "# Create tensor\n",
        "I, J, K = 5, 6, 7\n",
        "array_3d = np.random.rand(I * J * K).reshape((I, J, K)).astype(float)\n",
        "tensor = Tensor(array_3d)\n",
        "\n",
        "# Initialise algorithm\n",
        "algorithm = HOSVD()\n",
        "\n",
        "# Perform decomposing for selected multi-linear rank\n",
        "ml_rank = (4, 5, 6)\n",
        "tensor_tkd = algorithm.decompose(tensor, ml_rank)\n",
        "\n",
        "# Result preview\n",
        "print(tensor_tkd)\n",
        "\n",
        "print('\\n\\tFactor matrices')\n",
        "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
        "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
        "\n",
        "print('\\n\\tCore tensor')\n",
        "print(tensor_tkd.core)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4GohV8JOA2k"
      },
      "source": [
        "# Evaluation and reconstruction\n",
        "\n",
        "Tucker representation of an original tensor is almost always an approximation, regardless of which algorithm has been employed for performing decomposition. Thus, relative error of approximation is commonly used in order to evaluate performance of computational methods, i.e. the ratio between a Frobenious norms of residual and original tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wurnhFPBOA2k",
        "outputId": "55ea29ec-ad6a-4f0b-d511-4c3701af2943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative error of approximation = 0.255809658937915\n"
          ]
        }
      ],
      "source": [
        "# Compute residual tensor\n",
        "tensor_res = residual_tensor(tensor, tensor_tkd)\n",
        "\n",
        "# Compute error of approximation\n",
        "rel_error = tensor_res.frob_norm / tensor.frob_norm\n",
        "\n",
        "print(\"Relative error of approximation = {}\".format(rel_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x-ksf2DOA2k"
      },
      "source": [
        "## **Assigment 1**\n",
        "\n",
        "1. Create a tensor of order 4 with sizes of each mode being defined by prime numbers and  obtain a Tucker representation using HOOI algorithm with multi-linear (4, 10, 6, 2). Then calculation ratio between the number of elements in the original tensor and its Tucker form.\n",
        "\n",
        "1. For a tensor that consists of 1331 elements, which multi-linear rank guarantees a perfect reconstruction from its Tucker form and why. Is such choice reasonable for practical applications?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JND906ToOA2k"
      },
      "source": [
        "### Solution: Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "V7Zseq4kOA2k"
      },
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "I, J, K, N = 5, 17, 19, 7\n",
        "array_4d = np.random.rand(I * J * K* N).reshape((I, J, K, N)).astype(float)\n",
        "X = Tensor(array_4d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9KVrSOQVOA2k",
        "outputId": "cde07a00-1916-418a-afc1-be91b515ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode-0 factor matrix is of shape (5, 4)\n",
            "Mode-1 factor matrix is of shape (6, 5)\n",
            "Mode-2 factor matrix is of shape (7, 6)\n"
          ]
        }
      ],
      "source": [
        "# Perform decomposition\n",
        "\n",
        "\n",
        "# 初始化 HOOI 算法\n",
        "hooi = HOOI()\n",
        "decomp = hooi.decompose(X, (4, 10, 6, 2))\n",
        "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
        "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "e7Y0sZKoOA2l",
        "outputId": "06b7900f-7ee4-4633-d4cd-e69a76a316d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode-0 factor matrix is of shape (5, 4)\n",
            "Mode-1 factor matrix is of shape (6, 5)\n",
            "Mode-2 factor matrix is of shape (7, 6)\n",
            "ratio is 53.325471698113205(orignal_number/Tucker_number)\n"
          ]
        }
      ],
      "source": [
        "# Print ratio\n",
        "orignal_number = array_4d.size\n",
        "Tucker_number = 0\n",
        "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
        "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
        "    Tucker_number = Tucker_number + fmat.size\n",
        "Tucker_number = Tucker_number + tensor_tkd.core.size\n",
        "ratio = orignal_number/Tucker_number\n",
        "print('ratio is {}(orignal_number/Tucker_number)'.format(ratio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKjEW33COA2l"
      },
      "source": [
        "### Solution: Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qPdAEMIN3H6q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBsduUPYOA2l"
      },
      "source": [
        "**Include your answer with explanations here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(11^3= 1331)\n",
        "To make the reconstruction perfect, the multi-linear rank should be (11,11,11).As the factor matrix is achieved by SVD. So if the SVD is perfect, the reconctruction is perfect. The SVD only get the former R Singular Values. So if the R(i) always equal to the number of non-zero Singular Values(equals to the multi-liear rank), the information will not lose. So the multi-linear rank should be (11,11,11).\n",
        "However, this is not reasonable for application. Because if the core tensor is of the same size as the orignal tensor, the computational is increase and the information is not compressed, which is meaningless."
      ],
      "metadata": {
        "id": "5mWD5zWe28Li"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjZmwF66OA2l"
      },
      "source": [
        "# Application: Image compression\n",
        "\n",
        "Color images can be naturally represented as a tensor of order three with the shape `(height x width x channels)` where channels are, for example, Red, Blue and Green (RGB)\n",
        "\n",
        "<img src=\"https://github.com/IlyaKisil/dpm-coursework/blob/master/notebooks/imgs/image_to_base_colors.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "By keeping its original structure, allows to apply methods from multi-linear analysis. For instance, we can employ algorithms for Tucker decompositions in order to commress oringinal informaiton by varying values of desired multi-linear rank.\n",
        "\n",
        "```python\n",
        "# Get data in form of a Tensor\n",
        "car = get_image(item=\"car\", view=\"top\")\n",
        "tensor = Tensor(car)\n",
        "\n",
        "# Initialise algorithm and preform decomposition\n",
        "algorithm = HOSVD()\n",
        "tensor_tkd = algorithm.decompose(tensor, rank=(25, 25, 3))\n",
        "\n",
        "# Evaluate result\n",
        "tensor_res = residual_tensor(tensor, tensor_tkd)\n",
        "rel_error = tensor_res.frob_norm / tensor.frob_norm\n",
        "\n",
        "print(\"Relative error of approximation = {}\".format(rel_error))\n",
        "```\n",
        "\n",
        "When can also visually inspect image obtained by reconstructing the Tucker representation\n",
        "```python\n",
        "# Reconstruction\n",
        "tensor_rec = tensor_tkd.reconstruct()\n",
        "\n",
        "# Plot original and reconstructed images side by side\n",
        "plot_tensors(tensor, tensor_rec)\n",
        "```\n",
        "\n",
        "<img src=\"https://github.com/IlyaKisil/dpm-coursework/blob/master/notebooks/imgs/car_orig_vs_reconstructed_25_25_3.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ugD8k6OA2l"
      },
      "source": [
        "## **Assigment 2**\n",
        "For this assignment you are provided with function `get_image()` which requires two parameters: `item` and `view`. The valid values for former are **car** and **apple**, while the latter takes only **side** and **top**.\n",
        "\n",
        "1. Use multi-linear rank equal to `(50, 50, 2)` in order to obtain Tucker representations of images of the car and apple. Analyse results by visually inspecting their reconstructions.\n",
        "\n",
        "1. Use multi-linear rank equal to `(50, 50, 2)` in order to obtain Tucker representations of images of the apple taken from the top and from the side. Analyse results by visually inspecting their reconstructions.\n",
        "\n",
        "1. What would happen to the reconstruction if the value of multi-linear rank corresponding to the channel mode is decreased to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJF5YUEIOA2l"
      },
      "source": [
        "### Solution: Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMF2wOCoOA2l"
      },
      "outputs": [],
      "source": [
        "# Create tensors from images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8xZ2GDiOA2m"
      },
      "outputs": [],
      "source": [
        "# Perform decomposition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYc24LPnOA2m"
      },
      "outputs": [],
      "source": [
        "# Evaluate results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntpMdkwcOA2m"
      },
      "source": [
        "**Include your explanations here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRC7eqElOA2m"
      },
      "source": [
        "### Solution: Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtwNORZWOA2m"
      },
      "outputs": [],
      "source": [
        "# Create tensors from images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHQ0dbUNOA2m"
      },
      "outputs": [],
      "source": [
        "# Perform decomposition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjyvFkzSOA2m"
      },
      "outputs": [],
      "source": [
        "# Evaluate results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNXdNKvuOA2m"
      },
      "source": [
        "**Include your explanations here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HzbB5HnOA2m"
      },
      "source": [
        "### Solution: Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2Nxb1oOA2m"
      },
      "source": [
        "**Include your explanations here**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dpm-coursework",
      "language": "python",
      "name": "dpm-coursework"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc-showcode": false,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}